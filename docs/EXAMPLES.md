# Przyk≈Çady u≈ºycia

Ten dokument zawiera praktyczne przyk≈Çady u≈ºycia systemu ChatElioraSystem.

## üöÄ Szybki start

### 1. Podstawowa konwersacja

```csharp
// W ViewModel
var wiadomosc = ChatMessageFactory.User("Witaj, Eliora!");
Messages.Add(wiadomosc);

// System automatycznie:
// 1. Okre≈õla kategoriƒô rozmowy
// 2. ≈Åaduje kontekst z bazy wektorowej (RAG)
// 3. Wysy≈Ça do LLM z odpowiednim promptem
// 4. Wy≈õwietla odpowied≈∫ strumieniowo
```

### 2. R√≥≈ºne tryby prompt√≥w

System automatycznie wybiera odpowiedni prompt na podstawie kategorii:

- **Og√≥lna** - Dla rozm√≥w og√≥lnych
- **Kod** - Dla pyta≈Ñ o programowanie
- **Refleksyjna** - Dla refleksyjnych rozm√≥w
- **ArchitekturaKodu** - Dla pyta≈Ñ o architekturƒô

Mo≈ºesz te≈º rƒôcznie ustawiƒá temat w UI.

## üí° Przyk≈Çady u≈ºycia RAG

### Automatyczne wyszukiwanie kontekstu

Gdy zadajesz pytanie, system automatycznie:

1. Generuje zapytanie do bazy wektorowej
2. Wyszukuje podobne konwersacje (score > 0.85)
3. Dodaje je jako kontekst do promptu
4. LLM u≈ºywa tego kontekstu do lepszej odpowiedzi

**Przyk≈Çad:**
```
U≈ºytkownik: "Jak zrobiƒá dependency injection w C#?"
‚Üì
System wyszukuje w bazie wektorowej podobne pytania i odpowiedzi
‚Üì
Dodaje je jako kontekst systemowy
‚Üì
LLM odpowiada z uwzglƒôdnieniem wcze≈õniejszych rozm√≥w
```

### Zapis kontekstu

System automatycznie zapisuje wa≈ºne fragmenty rozm√≥w do bazy wektorowej:

```csharp
// Automatycznie przy ka≈ºdej odpowiedzi (je≈õli IsSaveToDbVec = true)
await _promptTypeOrchiestratorService.SaveStreamDataFromVectorDb(
    messages, 
    llmNo, 
    cancellationToken
);
```

## üé® Przyk≈Çady formatowania

### Kolorowanie tekstu

LLM mo≈ºe u≈ºywaƒá znacznik√≥w kolor√≥w w odpowiedziach:

```
<color=#FF5733>To jest czerwony tekst</color>
<color=#33FF57>To jest zielony tekst</color>
```

System automatycznie konwertuje je na formatowany tekst w UI.

### Markdown

Odpowiedzi mogƒÖ zawieraƒá Markdown:

```markdown
# Nag≈Ç√≥wek
**Pogrubiony tekst**
*Kursywa*
- Lista punktowana
```

System konwertuje Markdown na FlowDocument (WPF) lub odpowiedni format (MAUI).

## üîß Przyk≈Çady rozszerzania

### Dodanie nowego typu promptu

1. **Utw√≥rz interfejs w Domain:**
```csharp
public interface IRAGPromptMyNew : IRAGPromptBase
{
    string MyProperty { get; }
}
```

2. **Utw√≥rz implementacjƒô:**
```csharp
public class RAGPromptMyNew : BaseRAGPrompt, IRAGPromptMyNew
{
    public string MyProperty => "Warto≈õƒá";
    
    public override List<IChatMessage>? GetAdditionalChatMessage()
    {
        return new List<IChatMessage>
        {
            ChatMessageFactory.System("Tw√≥j system prompt")
        };
    }
}
```

3. **Utw√≥rz serwis:**
```csharp
public class PromptMyNewService : BasePromptService, IPromptMyNewService
{
    public PromptMyNewService(ILlmService llmService, IRAGPromptsGeneral rAGPromptsGeneral)
        : base(llmService, rAGPromptsGeneral)
    {
    }
}
```

4. **Zarejestruj w DependencyInjection:**
```csharp
services.AddSingleton<IRAGPromptMyNew, RAGPromptMyNew>();
services.AddScoped<IPromptMyNewService, PromptMyNewService>();
```

5. **Dodaj do orkiestratora:**
```csharp
case SesjaTematu.MyNewType:
    promptService = promptMyNewService;
    break;
```

### Dodanie nowej kolekcji Qdrant

```csharp
// W CollectionsNames.cs
public static class CollectionsNames
{
    public const string MyNewCollection = "my_new_collection";
}

// W QdrantVectorDbService
await _qdrantClient.CreateCollectionAsync(
    CollectionsNames.MyNewCollection,
    new VectorParams { Size = 1024, Distance = Distance.Cosine }
);
```

## üß™ Przyk≈Çady test√≥w

### Test serwisu z mockowaniem

```csharp
[Fact]
public void Serwis_Powinien_Wywolac_Zaleznosc()
{
    // Arrange
    var mockService = new Mock<IDependencyService>();
    mockService.Setup(s => s.GetValue()).Returns("test");
    
    var service = new MyService(mockService.Object);
    
    // Act
    var result = service.DoSomething();
    
    // Assert
    result.Should().Be("test");
    mockService.Verify(s => s.GetValue(), Times.Once);
}
```

## üì± Przyk≈Çady konfiguracji

### Konfiguracja dla r√≥≈ºnych ≈õrodowisk

**Development (lokalne):**
```json
{
  "ConnectionSettings": {
    "LlmServer": {
      "BaseUrl": "http://localhost:8123"
    },
    "Qdrant": {
      "RestUrl": "http://localhost:6333"
    }
  }
}
```

**Production (z Tailscale):**
```json
{
  "ConnectionSettings": {
    "LlmServer": {
      "BaseUrl": "http://your-device.tailXXXXXX.ts.net:8123"
    },
    "Qdrant": {
      "RestUrl": "http://your-device.tailXXXXXX.ts.net:6333"
    }
  }
}
```

## üéØ Przyk≈Çady u≈ºycia MCP

### Format MCP dla akcji RAG

```json
{
  "Akcja": {
    "Typ": "Odczyt",
    "Payload": "pytanie o dependency injection",
    "Metadata": {
      "Timestamp": "2025-01-01T12:00:00"
    }
  }
}
```

System automatycznie:
1. Parsuje JSON z odpowiedzi LLM
2. Wykonuje akcjƒô (odczyt/zapis)
3. Zwraca wyniki jako kontekst systemowy

---

**Wiƒôcej przyk≈Çad√≥w bƒôdzie dodawanych w miarƒô rozwoju projektu.**

